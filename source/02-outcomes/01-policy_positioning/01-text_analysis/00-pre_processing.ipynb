{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "from os import listdir\n",
    "from tqdm import tqdm\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_speeches = '/Users/cblanesg/cam.blanes Dropbox/Camila Blanes/Congressional-dataMX/data/01-collection_data/01-floor_speech/01-id_speakers/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 2/6 [00:00<00:02,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".DS_Store\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:01<00:00,  3.83it/s]\n"
     ]
    }
   ],
   "source": [
    "no_filter = []\n",
    "for i in tqdm(listdir(path_speeches)):\n",
    "    try:\n",
    "        with open(path_speeches + i) as f:\n",
    "            temp = json.load(f)\n",
    "            for j in temp:\n",
    "                no_filter.append(j)\n",
    "    except:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter only to Propietaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 133.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".DS_Store\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "path_id = '/Users/cblanesg/cam.blanes Dropbox/Camila Blanes/Congressional-dataMX/data/01-collection_data/00-id_data/00-id/'\n",
    "\n",
    "all_inc = []\n",
    "for i in tqdm(listdir(path_id)):\n",
    "    try:\n",
    "        with open(path_id + i) as f:\n",
    "            temp = json.load(f)\n",
    "            for j in temp:\n",
    "                if j['suplente_propietario'] == 'P':\n",
    "                    all_inc.append(j)\n",
    "    except:\n",
    "        print(i)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2500"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(pd.DataFrame(all_inc).id_legislador.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 2/6 [02:24<04:38, 69.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".DS_Store\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [05:31<00:00, 55.18s/it]\n"
     ]
    }
   ],
   "source": [
    "all_speeches = []\n",
    "for i in tqdm(listdir(path_speeches)):\n",
    "    try:\n",
    "        with open(path_speeches + i) as f:\n",
    "            temp = json.load(f)\n",
    "            for j in temp:\n",
    "                if j['id'] in list(pd.DataFrame(all_inc).id_legislador.unique()):\n",
    "                    all_speeches.append(j)\n",
    "    except:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40415, 41582)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_speeches), len(no_filter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing Steps\n",
    "    - lower\n",
    "    - numbers\n",
    "    - punctuation\n",
    "    - stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy ## Lemmatizer\n",
    "nlp_lemm = spacy.load(\"es_core_news_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.es import Spanish ## StopWords\n",
    "nlp = Spanish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.es.stop_words import STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    my_doc = nlp(text)\n",
    "    \n",
    "    token_list = []\n",
    "    for token in my_doc:\n",
    "        token_list.append(token.text)\n",
    "\n",
    "    filtered_sentence =[] \n",
    "\n",
    "    for word in token_list:\n",
    "        lexeme = nlp.vocab[word]\n",
    "        if lexeme.is_stop == False:\n",
    "            filtered_sentence.append(word)  \n",
    "    \n",
    "    full_text = ' '.join(filtered_sentence)\n",
    "    full_text = re.sub('[ ]+', ' ', full_text)\n",
    "    return(full_text)\n",
    "def apply_Lemmatization(text):\n",
    "    my_doc = nlp_lemm(text)\n",
    "    \n",
    "    lemma_word1 = [] \n",
    "    for token in my_doc:\n",
    "        lemma_word1.append(token.lemma_)\n",
    "\n",
    "    full_text = ' '.join(lemma_word1)\n",
    "    full_text = re.sub('[ ]+', ' ', full_text)\n",
    "    return(full_text)\n",
    "def remove_punctuation(text):\n",
    "    punctuation = {'!', '\"','#', '$','%','&',\"'\",'(',')','*','+',',','-','.','/',':',';','<','=','>','?','@','[','\\\\',']','^','_','`','{','|','}','~', '<'}\n",
    "    text = ''.join(i for i in text if i not in punctuation)\n",
    "    return(text)\n",
    "\n",
    "def remove_numbers(text):\n",
    "    text = re.sub('[0-9]+', '', text)\n",
    "    return(text)\n",
    "\n",
    "def strip_Whitespace(text):\n",
    "    text = re.sub('[ ]+', ' ', text)\n",
    "    text = re.sub('^[ ]+', '', text)\n",
    "    text = re.sub('[ ]+$', '', text)\n",
    "    return(text)\n",
    "def remove_accents(text):\n",
    "    text = unidecode(text)\n",
    "    return(text)\n",
    "def apply_lowercase(text):\n",
    "    text = text.lower()\n",
    "    return(text)\n",
    "\n",
    "def pre_processText(text):\n",
    "    clean = apply_lowercase(text)\n",
    "    clean = remove_numbers(clean)\n",
    "    clean = remove_punctuation(clean)\n",
    "    clean = remove_numbers(clean)\n",
    "    clean = remove_accents(clean)\n",
    "    clean = strip_Whitespace(clean)\n",
    "    clean = remove_stopwords(clean)\n",
    "    clean = apply_Lemmatization(clean)\n",
    "    return(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in tqdm(all_speeches):\n",
    "#    i['clean_speech'] = pre_processText(i['text_speech'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40415/40415 [55:10<00:00, 12.21it/s]   \n"
     ]
    }
   ],
   "source": [
    "legislatura60 = []\n",
    "legislatura61 = []\n",
    "legislatura62 = []\n",
    "legislatura63 = []\n",
    "legislatura64 = []\n",
    "\n",
    "for i in tqdm(all_speeches):\n",
    "    i['clean_speech'] = pre_processText(i['text_speech'])\n",
    "    \n",
    "    if i['legislatura'] == 60:\n",
    "        legislatura60.append(i)\n",
    "    elif i['legislatura'] == 61:\n",
    "        legislatura61.append(i)\n",
    "    elif i['legislatura'] == 62:\n",
    "        legislatura62.append(i)\n",
    "    elif i['legislatura'] == 63:\n",
    "        legislatura63.append(i)\n",
    "    elif i['legislatura'] == 64:\n",
    "        legislatura64.append(i)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/cblanesg/cam.blanes Dropbox/Camila Blanes/Congressional-dataMX/data/02-outcomes/01-policy_positioning/01-text_analysis/00-prep_data/legislatura60_speeches.json', 'w') as f:\n",
    "    json.dump(legislatura60, f)\n",
    "with open('/Users/cblanesg/cam.blanes Dropbox/Camila Blanes/Congressional-dataMX/data/02-outcomes/01-policy_positioning/01-text_analysis/00-prep_data/legislatura61_speeches.json', 'w') as f:\n",
    "    json.dump(legislatura61, f)\n",
    "with open('/Users/cblanesg/cam.blanes Dropbox/Camila Blanes/Congressional-dataMX/data/02-outcomes/01-policy_positioning/01-text_analysis/00-prep_data/legislatura62_speeches.json', 'w') as f:\n",
    "    json.dump(legislatura62, f)\n",
    "with open('/Users/cblanesg/cam.blanes Dropbox/Camila Blanes/Congressional-dataMX/data/02-outcomes/01-policy_positioning/01-text_analysis/00-prep_data/legislatura63_speeches.json', 'w') as f:\n",
    "    json.dump(legislatura63, f)\n",
    "with open('/Users/cblanesg/cam.blanes Dropbox/Camila Blanes/Congressional-dataMX/data/02-outcomes/01-policy_positioning/01-text_analysis/00-prep_data/legislatura64_speeches.json', 'w') as f:\n",
    "    json.dump(legislatura64, f)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge All Speeches by Speaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5329/5329 [00:00<00:00, 153352.59it/s]\n",
      " 55%|█████▍    | 259/471 [05:56<06:12,  1.76s/it]"
     ]
    }
   ],
   "source": [
    "agg_inc60 = {}\n",
    "for i in tqdm(legislatura60):\n",
    "    if i['id'] in agg_inc60.keys():\n",
    "        agg_inc60[i['id']].append(i['clean_speech'])\n",
    "    else:\n",
    "        agg_inc60[i['id']] = []\n",
    "        agg_inc60[i['id']].append(i['clean_speech'])\n",
    "        \n",
    "agg_dicts60 = []\n",
    "for x, y in tqdm(agg_inc60.items()):\n",
    "    temp = {}\n",
    "    temp['legislatura'] = 60\n",
    "    temp['id_incumbent'] = x\n",
    "    temp['speech'] = pre_processText(pre_processText(' '.join(y)))\n",
    "    agg_dicts60.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(agg_dicts60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(agg_dicts60[1]['speech'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/cblanesg/cam.blanes Dropbox/Camila Blanes/Congressional-dataMX/data/02-outcomes/01-policy_positioning/01-text_analysis/00-prep_data/aggregated_legislators/legislatura60_speech.json', 'w') as f:\n",
    "    json.dump(agg_dicts60, f)\n",
    "\n",
    "pd.DataFrame(agg_dicts60).to_excel('/Users/cblanesg/cam.blanes Dropbox/Camila Blanes/Congressional-dataMX/data/02-outcomes/01-policy_positioning/01-text_analysis/00-prep_data/aggregated_legislators/legislatura60_speech.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_inc61 = {}\n",
    "for i in tqdm(legislatura61):\n",
    "    if i['id'] in agg_inc61.keys():\n",
    "        agg_inc61[i['id']].append(i['clean_speech'])\n",
    "    else:\n",
    "        agg_inc61[i['id']] = []\n",
    "        agg_inc61[i['id']].append(i['clean_speech'])\n",
    "        \n",
    "agg_dicts61 = []\n",
    "for x, y in tqdm(agg_inc61.items()):\n",
    "    temp = {}\n",
    "    temp['legislatura'] = 61\n",
    "    temp['id_incumbent'] = x\n",
    "    temp['speech'] = pre_processText(pre_processText(' '.join(y)))\n",
    "    agg_dicts61.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(agg_dicts61)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/cblanesg/cam.blanes Dropbox/Camila Blanes/Congressional-dataMX/data/02-outcomes/01-policy_positioning/01-text_analysis/00-prep_data/aggregated_legislators/legislatura61_speech.json', 'w') as f:\n",
    "    json.dump(agg_dicts61, f)\n",
    "\n",
    "pd.DataFrame(agg_dicts61).to_excel('/Users/cblanesg/cam.blanes Dropbox/Camila Blanes/Congressional-dataMX/data/02-outcomes/01-policy_positioning/01-text_analysis/00-prep_data/aggregated_legislators/legislatura61_speech.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_inc62 = {}\n",
    "for i in tqdm(legislatura62):\n",
    "    if i['id'] in agg_inc62.keys():\n",
    "        agg_inc62[i['id']].append(i['clean_speech'])\n",
    "    else:\n",
    "        agg_inc62[i['id']] = []\n",
    "        agg_inc62[i['id']].append(i['clean_speech'])\n",
    "        \n",
    "agg_dicts62 = []\n",
    "for x, y in tqdm(agg_inc62.items()):\n",
    "    temp = {}\n",
    "    temp['legislatura'] = 62\n",
    "    temp['id_incumbent'] = x\n",
    "    temp['speech'] = pre_processText(pre_processText(' '.join(y)))\n",
    "    agg_dicts62.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(agg_dicts62)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/cblanesg/cam.blanes Dropbox/Camila Blanes/Congressional-dataMX/data/02-outcomes/01-policy_positioning/01-text_analysis/00-prep_data/aggregated_legislators/legislatura62_speech.json', 'w') as f:\n",
    "    json.dump(agg_dicts62, f)\n",
    "\n",
    "pd.DataFrame(agg_dicts62).to_excel('/Users/cblanesg/cam.blanes Dropbox/Camila Blanes/Congressional-dataMX/data/02-outcomes/01-policy_positioning/01-text_analysis/00-prep_data/aggregated_legislators/legislatura62_speech.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_inc63 = {}\n",
    "for i in tqdm(legislatura63):\n",
    "    if i['id']  in agg_inc63.keys():\n",
    "        agg_inc63[i['id']].append(i['clean_speech'])\n",
    "    else:\n",
    "        agg_inc63[i['id']] = []\n",
    "        agg_inc63[i['id']].append(i['clean_speech'])\n",
    "        \n",
    "agg_dicts63 = []\n",
    "for x, y in tqdm(agg_inc63.items()):\n",
    "    temp = {}\n",
    "    temp['legislatura'] = 63\n",
    "    temp['id_incumbent'] = x\n",
    "    temp['speech'] = pre_processText(pre_processText(' '.join(y)))\n",
    "    agg_dicts63.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(agg_dicts63)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/cblanesg/cam.blanes Dropbox/Camila Blanes/Congressional-dataMX/data/02-outcomes/01-policy_positioning/01-text_analysis/00-prep_data/aggregated_legislators/legislatura63_speech.json', 'w') as f:\n",
    "    json.dump(agg_dicts63, f)\n",
    "\n",
    "pd.DataFrame(agg_dicts63).to_excel('/Users/cblanesg/cam.blanes Dropbox/Camila Blanes/Congressional-dataMX/data/02-outcomes/01-policy_positioning/01-text_analysis/00-prep_data/aggregated_legislators/legislatura63_speech.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_inc64 = {}\n",
    "for i in tqdm(legislatura64):\n",
    "    if i['id'] in agg_inc64.keys():\n",
    "        agg_inc64[i['id']].append(i['clean_speech'])\n",
    "    else:\n",
    "        agg_inc64[i['id']] = []\n",
    "        agg_inc64[i['id']].append(i['clean_speech'])\n",
    "        \n",
    "agg_dicts64 = []\n",
    "for x, y in tqdm(agg_inc64.items()):\n",
    "    temp = {}\n",
    "    temp['legislatura'] = 64\n",
    "    temp['id_incumbent'] = x\n",
    "    temp['speech'] = pre_processText(pre_processText(' '.join(y)))\n",
    "    agg_dicts64.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(agg_dicts64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/cblanesg/cam.blanes Dropbox/Camila Blanes/Congressional-dataMX/data/02-outcomes/01-policy_positioning/01-text_analysis/00-prep_data/aggregated_legislators/legislatura64_speech.json', 'w') as f:\n",
    "    json.dump(agg_dicts64, f)\n",
    "\n",
    "pd.DataFrame(agg_dicts64).to_excel('/Users/cblanesg/cam.blanes Dropbox/Camila Blanes/Congressional-dataMX/data/02-outcomes/01-policy_positioning/01-text_analysis/00-prep_data/aggregated_legislators/legislatura64_speech.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

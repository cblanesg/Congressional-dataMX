{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook to create LDA of 40 topics with speeches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from operator import itemgetter\n",
    "import gensim\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from os import listdir\n",
    "from gensim.utils import simple_preprocess\n",
    "import gensim.corpora as corpora\n",
    "from gensim.models import CoherenceModel\n",
    "import spacy\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "# spacy for lemmatization\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('./../../../../../data/02-outcomes/01-policy_positioning/01-text_analysis/wordfish/01_lda/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_infrequent_words(data):\n",
    "    remove = list(pd.read_csv('/Users/cblanesg/cam.blanes Dropbox/Camila Blanes/Congressional-dataMX/data/02-outcomes/01-policy_positioning/01-text_analysis/wordfish/01_lda/remove_words.csv').remove_words)\n",
    "    extra_words = ['diputar', 'ley', \n",
    "              'articular', 'publicar', 'federal']\n",
    "    remove  = remove + extra_words\n",
    "    remove_list = '|'.join(remove)\n",
    "    regex = re.compile(r'\\b('+remove_list+r')\\b', flags=re.IGNORECASE)\n",
    "    \n",
    "    speech_clean = []\n",
    "    for x in tqdm(data.clean_speech):\n",
    "        clean = regex.sub('', x)\n",
    "        clean = re.sub('[ ]+', ' ', clean)\n",
    "        speech_clean.append(clean)\n",
    "    return(speech_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    \n",
    "    path = '/Users/cblanesg/cam.blanes Dropbox/Camila Blanes/Congressional-dataMX/data/02-outcomes/01-policy_positioning/01-text_analysis/01-clean_data/disaaggregated_data/'\n",
    "    data = []\n",
    "    for i in listdir(path):\n",
    "        if any(re.findall('json$', i)):\n",
    "            data.append(pd.read_json(path + i)[['id_speech', 'clean_speech']])\n",
    "           \n",
    "    data = pd.concat(data)\n",
    "    data = data[data['clean_speech'] != '']\n",
    "    return(data)\n",
    "\n",
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        # deacc=True removes punctuations\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40414/40414 [4:56:45<00:00,  2.27it/s]   \n"
     ]
    }
   ],
   "source": [
    "data_clean = remove_infrequent_words(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['data_clean'] = data_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_excel('/Users/cblanesg/Desktop/clean_speaches.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('/Users/cblanesg/Desktop/clean_speaches.json', 'w') as f:\n",
    "    json.dump(data.to_dict(), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lda_model_function(num_topics, corpus, id2word):\n",
    "    print('training model')\n",
    "    # Build LDA model\n",
    "    lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=num_topics)\n",
    "    \n",
    "    return(lda_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_bigrams(texts):\n",
    "    bigram = gensim.models.Phrases(data_words, min_count=5, threshold=100) # higher threshold fewer phrases.    \n",
    "    bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "def make_trigrams(texts):\n",
    "    trigram = gensim.models.Phrases(bigram[data_words], threshold=100)  \n",
    "    trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "\n",
    "def lemmatization(texts, nlp):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_])\n",
    "    return texts_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_corpus(data):\n",
    "        ## prepare inputs\n",
    "    print('loding data')\n",
    "    #data = load_data()\n",
    "    data = data.data_clean.values.tolist()\n",
    "    data_words = list(sent_to_words(data))\n",
    "    \n",
    "    # Create Dictionary\n",
    "    print('preparing input')\n",
    "    id2word = corpora.Dictionary(data_words)\n",
    "\n",
    "    # Create Corpus\n",
    "    texts = data_words\n",
    "\n",
    "    # Term Document Frequency\n",
    "    corpus = [id2word.doc2bow(text) for text in texts]\n",
    "    return(data_words, corpus, id2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_topics_docs(lda_model, corpus):\n",
    "    \n",
    "    all_topics = []\n",
    "    for i in tqdm(corpus):\n",
    "        main_topic = max(lda_model[i],key=itemgetter(1))[0]  \n",
    "        all_topics.append(main_topic + 1)\n",
    "    return(all_topics)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_visualization(num_topics, lda_model, corpus, id2word):\n",
    "    LDAvis_data_filepath = os.path.join('./lda_visualization/lda_prepared_'+str(num_topics))\n",
    "    \n",
    "    if 1 == 1:\n",
    "        LDAvis_prepared = pyLDAvis.gensim.prepare(lda_model, corpus, id2word)\n",
    "        with open(LDAvis_data_filepath, 'wb') as f:\n",
    "            pickle.dump(LDAvis_prepared, f)\n",
    "\n",
    "    # load the pre-prepared pyLDAvis data from disk\n",
    "    with open(LDAvis_data_filepath, 'rb') as f:\n",
    "        LDAvis_prepared = pickle.load(f)\n",
    "\n",
    "    pyLDAvis.save_html(LDAvis_prepared, './lda_visualization/lda_prepared_'+ str(num_topics) +'.html')\n",
    "    LDAvis_prepared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loding data\n",
      "preparing input\n"
     ]
    }
   ],
   "source": [
    "data_words, corpus30, id2word30 = load_corpus(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training model\n"
     ]
    }
   ],
   "source": [
    "lda_model30k = lda_model_function(30, corpus30, id2word30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.ldamulticore.LdaMulticore at 0x7fe6b13425b0>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_model30k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis.gensim\n",
    "import pickle \n",
    "import pyLDAvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.enable_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "obtain_visualization(30, lda_model30k, corpus30, id2word30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check best number of topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_text = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40414/40414 [01:57<00:00, 343.74it/s]\n"
     ]
    }
   ],
   "source": [
    "topics30k = obtain_topics_docs(lda_model30k, corpus30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['topics30k'] = topics30k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_speech</th>\n",
       "      <th>clean_speech</th>\n",
       "      <th>data_clean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topics30k</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1033</td>\n",
       "      <td>1033</td>\n",
       "      <td>1033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>808</td>\n",
       "      <td>808</td>\n",
       "      <td>808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>876</td>\n",
       "      <td>876</td>\n",
       "      <td>876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2626</td>\n",
       "      <td>2626</td>\n",
       "      <td>2626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1089</td>\n",
       "      <td>1089</td>\n",
       "      <td>1089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1151</td>\n",
       "      <td>1151</td>\n",
       "      <td>1151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1839</td>\n",
       "      <td>1839</td>\n",
       "      <td>1839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>544</td>\n",
       "      <td>544</td>\n",
       "      <td>544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>401</td>\n",
       "      <td>401</td>\n",
       "      <td>401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>743</td>\n",
       "      <td>743</td>\n",
       "      <td>743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2150</td>\n",
       "      <td>2150</td>\n",
       "      <td>2150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3527</td>\n",
       "      <td>3527</td>\n",
       "      <td>3527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>945</td>\n",
       "      <td>945</td>\n",
       "      <td>945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>179</td>\n",
       "      <td>179</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>623</td>\n",
       "      <td>623</td>\n",
       "      <td>623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2438</td>\n",
       "      <td>2438</td>\n",
       "      <td>2438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>398</td>\n",
       "      <td>398</td>\n",
       "      <td>398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2410</td>\n",
       "      <td>2410</td>\n",
       "      <td>2410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>603</td>\n",
       "      <td>603</td>\n",
       "      <td>603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>195</td>\n",
       "      <td>195</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>786</td>\n",
       "      <td>786</td>\n",
       "      <td>786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>244</td>\n",
       "      <td>244</td>\n",
       "      <td>244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>525</td>\n",
       "      <td>525</td>\n",
       "      <td>525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>3411</td>\n",
       "      <td>3411</td>\n",
       "      <td>3411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1353</td>\n",
       "      <td>1353</td>\n",
       "      <td>1353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>516</td>\n",
       "      <td>516</td>\n",
       "      <td>516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>5093</td>\n",
       "      <td>5093</td>\n",
       "      <td>5093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>700</td>\n",
       "      <td>700</td>\n",
       "      <td>700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1737</td>\n",
       "      <td>1737</td>\n",
       "      <td>1737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1471</td>\n",
       "      <td>1471</td>\n",
       "      <td>1471</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id_speech  clean_speech  data_clean\n",
       "topics30k                                     \n",
       "1               1033          1033        1033\n",
       "2                808           808         808\n",
       "3                876           876         876\n",
       "4               2626          2626        2626\n",
       "5               1089          1089        1089\n",
       "6               1151          1151        1151\n",
       "7               1839          1839        1839\n",
       "8                544           544         544\n",
       "9                401           401         401\n",
       "10               743           743         743\n",
       "11              2150          2150        2150\n",
       "12              3527          3527        3527\n",
       "13               945           945         945\n",
       "14               179           179         179\n",
       "15               623           623         623\n",
       "16              2438          2438        2438\n",
       "17               398           398         398\n",
       "18              2410          2410        2410\n",
       "19               603           603         603\n",
       "20               195           195         195\n",
       "21               786           786         786\n",
       "22               244           244         244\n",
       "23               525           525         525\n",
       "24              3411          3411        3411\n",
       "25              1353          1353        1353\n",
       "26               516           516         516\n",
       "27              5093          5093        5093\n",
       "28               700           700         700\n",
       "29              1737          1737        1737\n",
       "30              1471          1471        1471"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby(['topics30k']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/cblanesg/Desktop/clean_speaches_topics.json', 'w') as f:\n",
    "    json.dump(data.to_dict(), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_excel('/Users/cblanesg/Desktop/clean_speaches_topics.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(9, 0.037157632), (16, 0.07184446), (22, 0.88363147)]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_model30k[corpus30[4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_speech</th>\n",
       "      <th>clean_speech</th>\n",
       "      <th>data_clean</th>\n",
       "      <th>topics30k</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c722e947-9e5e-3eae-8e47-e696d7d93af3</td>\n",
       "      <td>muchisimas gracia senor presidente companeras ...</td>\n",
       "      <td>muchisimas senor y jefe familia luchar a dific...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7ef74c2e-c448-3edf-aeae-17c21d0001c9</td>\n",
       "      <td>agradecer presidente compromiso partir politic...</td>\n",
       "      <td>agradecer compromiso politicos agradecerle a j...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3b25563c-cbf7-39a7-8bde-9aa982717eea</td>\n",
       "      <td>muchisimas gracia venia diputar presidente com...</td>\n",
       "      <td>muchisimas asamblea tribuna posicionamiento re...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b365b74e-8392-3260-978f-6b1722d4e363</td>\n",
       "      <td>tarde a permiso senora presidente companeras y...</td>\n",
       "      <td>tarde a senora y a nombrar revolucionario inst...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ed1f1f7e-aeed-3a04-83a2-abe7fc41be06</td>\n",
       "      <td>venia senor presidente companeras diputar comp...</td>\n",
       "      <td>senor alegrar soberania votar unanimidad dict...</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8196</th>\n",
       "      <td>b235ddf6-d048-37b8-9bc1-dff953c9ddc9</td>\n",
       "      <td>gracia presidente reservar articular ley siste...</td>\n",
       "      <td>reservar sistema seguridad proponer derogacio...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8197</th>\n",
       "      <td>dfdf3a22-e9ff-31c5-940e-9e0dbdacccbd</td>\n",
       "      <td>gracia presidente diputar secretario bienvenid...</td>\n",
       "      <td>secretario bienvenido gustar recibir a mujer ...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8198</th>\n",
       "      <td>6a7a24f3-46f3-38a6-b9d0-29848f8fca83</td>\n",
       "      <td>gracia presidente diputar empezar saludar resp...</td>\n",
       "      <td>empezar saludar respetar secretario alfonso d...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8199</th>\n",
       "      <td>5f9aced1-def4-3fa7-aac2-6cabace1342b</td>\n",
       "      <td>gracia diputar presidente diputar sumision mie...</td>\n",
       "      <td>sumision miedo silenciar comodidad terminar y...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8200</th>\n",
       "      <td>8e417b1a-3f2c-3412-978f-c8dc88a94b56</td>\n",
       "      <td>gracia presidente saludo a companeras y compan...</td>\n",
       "      <td>saludo a y legislador tribuna representacion ...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40414 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id_speech  \\\n",
       "0     c722e947-9e5e-3eae-8e47-e696d7d93af3   \n",
       "1     7ef74c2e-c448-3edf-aeae-17c21d0001c9   \n",
       "2     3b25563c-cbf7-39a7-8bde-9aa982717eea   \n",
       "3     b365b74e-8392-3260-978f-6b1722d4e363   \n",
       "4     ed1f1f7e-aeed-3a04-83a2-abe7fc41be06   \n",
       "...                                    ...   \n",
       "8196  b235ddf6-d048-37b8-9bc1-dff953c9ddc9   \n",
       "8197  dfdf3a22-e9ff-31c5-940e-9e0dbdacccbd   \n",
       "8198  6a7a24f3-46f3-38a6-b9d0-29848f8fca83   \n",
       "8199  5f9aced1-def4-3fa7-aac2-6cabace1342b   \n",
       "8200  8e417b1a-3f2c-3412-978f-c8dc88a94b56   \n",
       "\n",
       "                                           clean_speech  \\\n",
       "0     muchisimas gracia senor presidente companeras ...   \n",
       "1     agradecer presidente compromiso partir politic...   \n",
       "2     muchisimas gracia venia diputar presidente com...   \n",
       "3     tarde a permiso senora presidente companeras y...   \n",
       "4     venia senor presidente companeras diputar comp...   \n",
       "...                                                 ...   \n",
       "8196  gracia presidente reservar articular ley siste...   \n",
       "8197  gracia presidente diputar secretario bienvenid...   \n",
       "8198  gracia presidente diputar empezar saludar resp...   \n",
       "8199  gracia diputar presidente diputar sumision mie...   \n",
       "8200  gracia presidente saludo a companeras y compan...   \n",
       "\n",
       "                                             data_clean  topics30k  \n",
       "0     muchisimas senor y jefe familia luchar a dific...          1  \n",
       "1     agradecer compromiso politicos agradecerle a j...          5  \n",
       "2     muchisimas asamblea tribuna posicionamiento re...          7  \n",
       "3     tarde a senora y a nombrar revolucionario inst...         12  \n",
       "4      senor alegrar soberania votar unanimidad dict...         23  \n",
       "...                                                 ...        ...  \n",
       "8196   reservar sistema seguridad proponer derogacio...         27  \n",
       "8197   secretario bienvenido gustar recibir a mujer ...         27  \n",
       "8198   empezar saludar respetar secretario alfonso d...         27  \n",
       "8199   sumision miedo silenciar comodidad terminar y...         18  \n",
       "8200   saludo a y legislador tribuna representacion ...         27  \n",
       "\n",
       "[40414 rows x 4 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

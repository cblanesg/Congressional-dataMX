{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import uuid\n",
    "import re\n",
    "import datetime \n",
    "from datetime import date\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_links_legislaturas(legislaturas):\n",
    "    \"\"\"\n",
    "    Parametros:\n",
    "    -----------\n",
    "    legislatura: list of int numbers of legislatura\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    lista de diccionario con los a el htmls de los debates legislativos\n",
    "    \"\"\"\n",
    "    all_data = []\n",
    "\n",
    "    for legislatura in legislaturas:\n",
    "        link_debates = 'http://cronica.diputados.gob.mx/DDebates/' + str(legislatura) + '/index.html'\n",
    "\n",
    "        r = requests.get(link_debates)\n",
    "        soup = BeautifulSoup(r.content, 'html.parser')\n",
    "\n",
    "        links_sesiones = []\n",
    "        type_sesion = []\n",
    "        urls = []\n",
    "        for h in soup.findAll('a'):\n",
    "            links_sesiones.append('http://cronica.diputados.gob.mx/DDebates/' + str(legislatura) + '/' + h.get('href'))\n",
    "            type_sesion.append(re.sub('\\xa0', '', h.text))\n",
    "            urls.append(h.get('href'))\n",
    "\n",
    "\n",
    "        for x, y, urls in zip(links_sesiones, type_sesion, urls):\n",
    "            r = requests.get(x)\n",
    "            soup = BeautifulSoup(r.content, 'html.parser')\n",
    "\n",
    "            for i in soup.findAll('a'):\n",
    "                year_session = re.findall('[0-9]{4}', soup.findAll('tbody')[1].find('tr').text)[0]\n",
    "                link_ = 'http://cronica.diputados.gob.mx/DDebates/' + str(legislatura)+'/'+ re.sub('index[.]html', '', urls) +i.get('href')\n",
    "\n",
    "                fecha_speech = get_date_speech(year_session, link_, i.text)\n",
    "\n",
    "                temp = {}\n",
    "                temp['id_debate'] = str(uuid.uuid3(uuid.NAMESPACE_URL,link_))\n",
    "                temp['legislatura'] = legislatura\n",
    "                temp['date_debate'] = fecha_speech\n",
    "                temp['type_sesion'] = y\n",
    "                temp['link_debate'] = link_\n",
    "                all_data.append(temp)\n",
    "    return(all_data)\n",
    "\n",
    "def get_date_speech(year_session, link_speech, text_day):\n",
    "    day_speech = re.findall('[0-9]+', text_day)[0]\n",
    "    month_speech = month_to_number(link_speech.split('/')[-2:][0])\n",
    "    return(datetime.date(int(year_session), int(month_speech), int(day_speech)))\n",
    "\n",
    "def month_to_number(m):\n",
    "    if m == 'ene':\n",
    "        return(1)\n",
    "    elif m == 'feb':\n",
    "        return(2)\n",
    "    elif m == 'mar':\n",
    "        return(3)\n",
    "    elif m == 'abr':\n",
    "        return(4)\n",
    "    elif m == 'may':\n",
    "        return(5)\n",
    "    elif m == 'jun':\n",
    "        return(6)\n",
    "    elif m == 'jul':\n",
    "        return(7)\n",
    "    elif m == 'ago':\n",
    "        return(8)\n",
    "    elif m == 'sep':\n",
    "        return(9)\n",
    "    elif m == 'oct':\n",
    "        return(10)\n",
    "    elif m == 'nov':\n",
    "        return(11)\n",
    "    elif m == 'dic':\n",
    "        return(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_links_legislaturas([63, 64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_texto_debate(link):\n",
    "    r = requests.get(link)\n",
    "    soup = BeautifulSoup(r.content, 'html.parser')\n",
    "    contenido_debate = soup.findAll(\"div\", {\"class\": \"Contenido\"})[0].text\n",
    "    \n",
    "    dict_contenidos = {}\n",
    "    for i in contenido_debate.split('\\n\\n\\n \\n'):\n",
    "        try:\n",
    "            name_tema = re.sub('\\n', '', re.findall('^[A-Z].*\\n',i)[0])\n",
    "            text_all = re.sub(name_tema, '', i)\n",
    "            text_all = re.sub('[ ]+$', '', re.sub('^[ ]+', '', re.sub('[ ]+', ' ', re.sub('\\n+', ' ', text_all))))\n",
    "            dict_contenidos[name_tema] = text_all\n",
    "        except:\n",
    "            continue\n",
    "    dict_contenidos['id_debate'] = str(uuid.uuid3(uuid.NAMESPACE_URL,link))\n",
    "    #main_text = []\n",
    "    #for x in dict_contenidos.values():\n",
    "    #    main_text.append(x)\n",
    "    #return(re.sub('\\n', ' ', ' '.join(main_text)))\n",
    "    print(len(dict_contenidos.keys()))\n",
    "    return(dict_contenidos)\n",
    "\n",
    "\n",
    "def obtain_text_sesion(link):\n",
    "    r = requests.get(link)\n",
    "    soup = BeautifulSoup(r.content, 'html.parser')\n",
    "    \n",
    "    try:\n",
    "        links_volumenes = []\n",
    "        for h in soup.findAll('a'):\n",
    "            if any(re.findall('Vol√∫men', h.text)):\n",
    "                links_volumenes.append(h.get('href'))\n",
    "        \n",
    "        real_link = '/'.join(link.split('/')[:-1]) + '/' + links_volumenes[0]\n",
    "        \n",
    "        texto_debate = obtain_texto_debate(real_link)\n",
    "        return(texto_debate)\n",
    "    except:\n",
    "        return(obtain_texto_debate(link))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "10\n",
      "27\n",
      "18\n",
      "13\n",
      "11\n",
      "21\n",
      "33\n",
      "28\n"
     ]
    }
   ],
   "source": [
    "for i in df_data.link_debate:\n",
    "    try:\n",
    "        obtain_text_sesion(i)\n",
    "    except:\n",
    "        print(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
